{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aid.ipynb\n",
    "# Author: Kyle Larson\n",
    "# Purpose top secret\n",
    "import numpy as np \n",
    "import soundfile as sf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD\n",
    "# Stack overflow was consulted in order to parse '.flac' \n",
    "#path = '../input/rfcx-species-audio-detection/train/00204008d.flac'\n",
    "#data, samplerate = sf.read(path) #this method is thanks to Harry Moreno \n",
    "#from his Stack Overflow response on June 13 '18 at the following URL:\n",
    "#https://stackoverflow.com/questions/50804170/load-flac-file-in-python-same-as-scipy-or-librosa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00204008d.flac</th>\n",
       "      <th>003b04435.flac</th>\n",
       "      <th>003bec244.flac</th>\n",
       "      <th>005f1f9a5.flac</th>\n",
       "      <th>006ab765f.flac</th>\n",
       "      <th>0072f0839.flac</th>\n",
       "      <th>0079ff47b.flac</th>\n",
       "      <th>007f87ba2.flac</th>\n",
       "      <th>00834f88e.flac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.007538</td>\n",
       "      <td>0.002106</td>\n",
       "      <td>0.008301</td>\n",
       "      <td>0.015076</td>\n",
       "      <td>-0.009308</td>\n",
       "      <td>-0.001404</td>\n",
       "      <td>-0.028168</td>\n",
       "      <td>0.047791</td>\n",
       "      <td>-0.067291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007111</td>\n",
       "      <td>0.007935</td>\n",
       "      <td>0.028137</td>\n",
       "      <td>0.026093</td>\n",
       "      <td>-0.009949</td>\n",
       "      <td>-0.000092</td>\n",
       "      <td>0.016174</td>\n",
       "      <td>0.030731</td>\n",
       "      <td>-0.066895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006165</td>\n",
       "      <td>0.005188</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>0.029877</td>\n",
       "      <td>-0.011444</td>\n",
       "      <td>0.003693</td>\n",
       "      <td>0.070160</td>\n",
       "      <td>0.016846</td>\n",
       "      <td>-0.059387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.010773</td>\n",
       "      <td>0.006744</td>\n",
       "      <td>0.019836</td>\n",
       "      <td>0.038025</td>\n",
       "      <td>-0.010559</td>\n",
       "      <td>-0.004700</td>\n",
       "      <td>0.078705</td>\n",
       "      <td>-0.004059</td>\n",
       "      <td>-0.030823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.004669</td>\n",
       "      <td>0.004028</td>\n",
       "      <td>-0.002319</td>\n",
       "      <td>0.042023</td>\n",
       "      <td>-0.011383</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.102417</td>\n",
       "      <td>-0.026215</td>\n",
       "      <td>0.000427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   00204008d.flac  003b04435.flac  003bec244.flac  005f1f9a5.flac  \\\n",
       "0        0.007538        0.002106        0.008301        0.015076   \n",
       "1        0.007111        0.007935        0.028137        0.026093   \n",
       "2        0.006165        0.005188        0.024689        0.029877   \n",
       "3        0.010773        0.006744        0.019836        0.038025   \n",
       "4        0.004669        0.004028       -0.002319        0.042023   \n",
       "\n",
       "   006ab765f.flac  0072f0839.flac  0079ff47b.flac  007f87ba2.flac  \\\n",
       "0       -0.009308       -0.001404       -0.028168        0.047791   \n",
       "1       -0.009949       -0.000092        0.016174        0.030731   \n",
       "2       -0.011444        0.003693        0.070160        0.016846   \n",
       "3       -0.010559       -0.004700        0.078705       -0.004059   \n",
       "4       -0.011383        0.002777        0.102417       -0.026215   \n",
       "\n",
       "   00834f88e.flac  \n",
       "0       -0.067291  \n",
       "1       -0.066895  \n",
       "2       -0.059387  \n",
       "3       -0.030823  \n",
       "4        0.000427  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "file_name_list = os.listdir('C:/Users/admin/anaconda3/01 PROJECTS/Audio ID')\n",
    "#the following sequential open strategy was found not to work due to frequency mismatch between id_data and filenames\n",
    "ignore = ['.git', '.ipynb_checkpoints', 'train.zip']\n",
    "new_df1 = pd.DataFrame({file_name_list[2]:[]})\n",
    "for i in range(len(file_name_list)):#len(id_data) #10 files ~ 5 seconds w/ RAM ~25%\n",
    "    if(file_name_list[i]!=ignore[0] and file_name_list[i]!=ignore[1] and file_name_list[i]!=ignore[2]):\n",
    "        data, samplerate = sf.read('C:/Users/admin/anaconda3/01 PROJECTS/Audio ID/' +file_name_list[i])\n",
    "        new_df1[file_name_list[i]] = np.array(data)\n",
    "    if(i==10):\n",
    "        break\n",
    "new_df1.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#at 1 min 5 sec the following error occured:\n",
    "#Your notebook tried to allocate more memory than is available. It has restarted.\n",
    "#thats 65 seconds or 130 files that can occupy ram at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]]\n",
      "[[1. 2.]\n",
      " [3. 4.]\n",
      " [5. 6.]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import array\n",
    "from scipy.linalg import svd\n",
    "from numpy import dot\n",
    "from numpy import diag\n",
    "from numpy import zeros\n",
    "A = array([[1,2],[3,4],[5,6]])\n",
    "print(A)\n",
    "U, s, VT = svd(A)\n",
    "Sigma = zeros((A.shape[0], A.shape[1]))\n",
    "Sigma[:A.shape[1], :A.shape[1]] = diag(s)\n",
    "B = U.dot(Sigma.dot(VT))\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_df1.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41.13421631-0.j         10.64642932+0.25820614j  9.2332184 -0.19021899j\n",
      " ...  7.33564754-1.87112699j  9.2332184 +0.19021899j\n",
      " 10.64642932-0.25820614j]\n",
      "[40.94290161 -0.j         -7.09001743+15.60606578j\n",
      " -3.8866546  +6.41422956j ...  0.11746973 -7.08458867j\n",
      " -3.8866546  -6.41422956j -7.09001743-15.60606578j]\n",
      "[73.42666626 -0.j         -7.19791793+10.73032501j\n",
      "  6.07912089+16.33527279j ... 10.57079271 -7.26532391j\n",
      "  6.07912089-16.33527279j -7.19791793-10.73032501j]\n",
      "[ 338.96380615 -0.j         -195.86090338+22.05340036j\n",
      "  234.4222708 -23.29121672j ... -221.97790813-58.74850902j\n",
      "  234.4222708 +23.29121672j -195.86090338-22.05340036j]\n",
      "[12.26766968-0.j         -0.78639117-5.08030292j  5.61737918+2.27025603j\n",
      " ... 10.45377886+5.74960348j  5.61737918-2.27025603j\n",
      " -0.78639117+5.08030292j]\n",
      "[-23.9730835 -0.j          14.18005352-0.28015113j\n",
      "  16.20927771-4.44195174j ...  14.91674952+1.15132006j\n",
      "  16.20927771+4.44195174j  14.18005352+0.28015113j]\n",
      "[-48.27636719-0.j          32.46140868+0.36736206j\n",
      "  32.94666852+0.47735684j ...  26.71753988-3.71668693j\n",
      "  32.94666852-0.47735684j  32.46140868-0.36736206j]\n"
     ]
    }
   ],
   "source": [
    "#the plan is to use a fft (Fast Forier Transform) to halve the number of datapoints to reduce compute time\n",
    "#then use an SVD (singular value decomposition) to prioritize the points that are principle components\n",
    "from scipy.fft import fft, ifft\n",
    "\n",
    "for i in range(2,len(new_df1.loc[0])):\n",
    "    x = np.array(new_df1.loc[:][file_name_list[i]])\n",
    "    print(fft(x))\n",
    "#time for this 9 was <1sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
